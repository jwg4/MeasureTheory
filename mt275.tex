\frfilename{mt275.tex}
\versiondate{3.12.12}

\def\chaptername{Probability theory}
\def\sectionname{Martingales}
\copyrightdate{2001}

\newsection{275}

This chapter so far has been dominated by independent sequences of
random variables.   I now turn to another of the remarkable concepts to
which probabilistic intuitions have led us.   Here we study evolving
systems, in which we gain progressively more information as time
progresses.   I give the basic theorems on pointwise convergence of
martingales (275F-275H, %275F 275G 275H
275K) and a very brief account of `stopping times'
(275L-275P). %275L 275M 275N 275O 275P

\leader{275A}{Definition} Let $(\Omega,\Sigma,\mu)$ be a probability
space with completion $(\Omega,\hat\Sigma,\hat\mu)$, and
$\sequencen{\Sigma_n}$ a non-decreasing sequence of
$\sigma$-subalgebras of $\hat\Sigma$.   \cmmnt{(Such sequences
$\sequencen{\Sigma_n}$ are called {\bf filtrations}.)}
A {\bf martingale adapted to
$\sequencen{\Sigma_n}$} is a sequence $\sequencen{X_n}$ of integrable
real-valued random variables on $\Omega$ such that (i)
$\dom X_n\in\Sigma_n$ and $X_n$ is
$\Sigma_n$-measurable for each $n\in\Bbb N$
(ii) whenever $m\le n\in\Bbb N$
and $E\in\Sigma_m$ then $\int_EX_{n}=\int_EX_m$.

\cmmnt{Note that for (ii)
it is enough if $\int_EX_{n+1}=\int_EX_n$ whenever $n\in\Bbb N$
and $E\in\Sigma_n$.}

\leader{275B}{Examples }\cmmnt{We have seen many contexts in which
such sequences appear naturally;  here are a few.

\medskip

}{\bf (a)} Let $(\Omega,\Sigma,\mu)$ be a probability space
and $\sequencen{\Sigma_n}$ a non-decreasing sequence of
$\sigma$-subalgebras of $\Sigma$.   Let $X$ be any
real-valued random variable on $\Omega$ with finite expectation, and for
each $n\in\Bbb N$ let
$X_n$ be a conditional expectation of $X$ on $\Sigma_n$\cmmnt{, as in
\S233}.   Subject to the conditions that $\dom X_n\in\Sigma_n$ and $X_n$
is actually $\Sigma_n$-measurable for each $n$\cmmnt{ (a purely
technical
point -- see 232He)}, $\sequencen{X_n}$ will be a martingale adapted to
$\sequencen{\Sigma_n}$\cmmnt{, because
$\int_EX_{n+1}=\int_EX=\int_EX_n$ whenever $E\in\Sigma_n$}.

\spheader 275Bb Let $(\Omega,\Sigma,\mu)$ be a probability space
and $\sequencen{X_n}$ an independent sequence of random
variables all with zero expectation.   For each $n\in\Bbb N$ let
$\tilde\Sigma_n$ be the
$\sigma$-algebra generated by $\bigcup_{i\le n}\Sigma_{X_i}$, writing
$\Sigma_{X_i}$ for the
$\sigma$-algebra defined by $X_i$\cmmnt{ (272C)}, and set
$S_n=X_0+\ldots+X_n$.   Then $\sequencen{S_n}$ is a martingale adapted
to $\tilde\Sigma_n$.   \cmmnt{(Use 272K to see that $\Sigma_{X_{n+1}}$
is independent of $\tilde\Sigma_n$, so that
$\int_EX_{n+1}=\int X_{n+1}\times\chi E=0$ for every
$E\in\tilde\Sigma_n$, by 272R.)}

\spheader 275Bc Let $(\Omega,\Sigma,\mu)$ be a probability space
and $\sequencen{X_n}$ an independent sequence of
random variables all with expectation $1$.   For each $n\in\Bbb N$ let
$\tilde\Sigma_n$ be the
$\sigma$-algebra generated by $\bigcup_{i\le n}\Sigma_{X_i}$, writing
$\Sigma_{X_i}$ for the
$\sigma$-algebra defined by $X_i$, and set
$W_n=X_0\times\ldots\times X_n$.   Then $\sequencen{W_n}$ is a
martingale adapted to $\sequencen{\tilde\Sigma_n}$.
%\sequencen{\tilde\Sigma_n} is the {\bf natural filtration} for
%\sequencen{X_n}

\leader{275C}{Remarks }\cmmnt{{\bf (a)} It seems appropriate to the
concept of a random variable $X$ being `adapted' to a
$\sigma$-algebra $\Sigma$ to require that $\dom X\in\Sigma$ and that $X$
should be $\Sigma$-measurable, even though this may mean that other
random variables, equal almost everywhere to $X$, may fail to be
`adapted' to $\Sigma$.

\spheader 275Cb Technical problems of this kind evaporate, of
course, if all
$\mu$-negligible subsets of $X$ belong to $\Sigma_0$.   But examples
such as 275Bb make it seem unreasonable to insist on such a
simplification as a general rule.

\header{275Cc}}%end of comment
{\bf (c)} The concept of `martingale' can readily be
extended to other index sets than $\Bbb N$;  indeed, if $I$ is any
partially ordered set, we can say that $\langle X_i\rangle_{i\in I}$ is
a martingale on $(\Omega,\Sigma,\mu)$ adapted to
$\langle\Sigma_i\rangle_{i\in I}$ if (i) each $\Sigma_i$ is a
$\sigma$-subalgebra of $\hat\Sigma$ (ii) each $X_i$ is an integrable
real-valued $\Sigma_i$-measurable random variable such that
$\dom X_i\in\Sigma_i$ (iii) whenever $i\le j$ in $I$, then
$\Sigma_i\subseteq\Sigma_j$ and $\int_EX_i=\int_EX_j$ for every
$E\in\Sigma_i$.   \cmmnt{The principal case, after $I=\Bbb N$, is
$I=\coint{0,\infty}$;  $I=\Bbb Z$ also is interesting, and I think it is
fair to say that the most important ideas can already be expressed in
theorems about martingales indexed by finite sets $I$.   But in this
volume I will generally take martingales to be indexed by $\Bbb N$.
}%end of comment

\spheader 275Cd Given just a sequence $\sequencen{X_n}$ of
integrable
real-valued random variables on a probability space
$(\Omega,\Sigma,\mu)$, we can say simply that $\sequencen{X_n}$ is a
{\bf martingale} on $(\Omega,\Sigma,\mu)$ if there is some
non-decreasing
sequence $\sequencen{\Sigma_n}$ of $\sigma$-subalgebras of
$\hat\Sigma$\cmmnt{ (the completion of $\Sigma$)} such that
$\sequencen{X_n}$ is a martingale
adapted to $\sequencen{\Sigma_n}$.   If we write $\tilde\Sigma_n$ for
the $\sigma$-algebra generated by $\bigcup_{i\le n}\Sigma_{X_i}$, where
$\Sigma_{X_i}$ is the
$\sigma$-algebra defined by $X_i$\cmmnt{, as in 275Bb},
then\cmmnt{ it is easy to see that} $\sequencen{X_n}$ is a martingale
iff it is a martingale adapted to
$\sequencen{\tilde\Sigma_n}$.

\spheader 275Ce Continuing from (d),\cmmnt{ it is also easy to
see that} if $\sequencen{X_n}$
is a martingale on $(\Omega,\Sigma,\mu)$, and
$X'_n\eae X_n$ for every $n$, then $\sequencen{X'_n}$ is a martingale
on $(\Omega,\Sigma,\mu)$.   \cmmnt{(The point is that if
$\sequencen{X_n}$ is
adapted to $\sequencen{\Sigma_n}$, then both $\sequencen{X_n}$ and
$\sequencen{X'_n}$ are adapted to $\sequencen{\hat\Sigma_n}$, where

\Centerline{$\hat\Sigma_n
=\{E\symmdiff F:E\in\Sigma_n,\,F\text{ is negligible}\}$.)}

\noindent}Consequently
we have a concept of `martingale' as a sequence in $L^1(\mu)$, saying
that a sequence $\sequencen{X_n^{\ssbullet}}$ in $L^1(\mu)$ is a
martingale iff $\sequencen{X_n}$ is a martingale.

\cmmnt{Nevertheless, I think that the concept of `martingale
adapted
to a sequence of $\sigma$-algebras' is the primary one, since in all the
principal applications the $\sigma$-algebras reflect some essential
aspect of the problem, which may not be fully encompassed by the random
variables alone.}

\cmmnt{
\spheader 275Cf The word `martingale' originally (in English;
the history in French is more complex) referred to
a strap used to prevent a horse from throwing its head back.   Later it
was used as the name of a gambling system in which the gambler doubles
his stake each time he loses, and (in French) as a general term for
gambling systems.   These may be regarded as a class of
`stopped-time martingales', as described in
275L-275P %275L 275M 275N 275O 275P
below.
}%end of comment

\leader{275D}{}\cmmnt{ A large part of the theory of martingales
consists of inequalities of various kinds.   I give two of the most
important, both due to J.L.Doob.   (See also 276Xa-276Xb.)

\medskip

\noindent}{\bf Lemma} Let $(\Omega,\Sigma,\mu)$ be a probability space,
and $\sequencen{X_n}$ a
martingale on $\Omega$.   Fix $n\in\Bbb N$ and set
$X^*=\max(X_0,\ldots,X_n)$.   Then for any $\epsilon>0$,

\Centerline{$\Pr(X^*\ge\epsilon)
\le\Bover1{\epsilon}\Expn(X_n^+)$,}

\noindent writing $X_n^+=\max({0},X_n)$.

\proof{ Write $\hat\mu$ for the completion of $\mu$, and $\hat\Sigma$
for its domain.   Let $\sequencen{\Sigma_n}$ be a
non-decreasing sequence of
$\sigma$-subalgebras of $\hat\Sigma$ to which $\sequencen{X_n}$ is
adapted.   For each $i\le n$ set

\Centerline{$E_i=\{\omega:\omega\in\dom
X_i,\,X_i(\omega)\ge\epsilon\}$,}

\Centerline{$F_i=E_i\setminus\bigcup_{j<i}E_j$.}

\noindent Then $F_0,\ldots,F_n$ are disjoint and
$F=\bigcup_{i\le n}F_i=\bigcup_{i\le n}E_i$;  moreover, writing $H$ for the conegligible set $\bigcap_{i\le n}\dom X_i$,

\Centerline{$\{\omega:X^*(\omega)\ge\epsilon\}=F\cap H$,}

\noindent so that

\Centerline{$\Pr(X^*\ge\epsilon)=
\hat\mu\{\omega:X^*(\omega)\ge\epsilon\}
=\hat\mu F=\sum_{i=0}^n\hat\mu F_i$.}

\noindent On the other hand, $E_i$ and $F_i$ belong to $\Sigma_i$ for
each $i\le n$, so

\Centerline{$\int_{F_i}X_n=\int_{F_i}X_i\ge \epsilon\hat\mu F_i$}

\noindent for every $i$, and

\Centerline{$\epsilon\hat\mu F=\epsilon\sum_{i=0}^n\hat\mu F_i
\le\sum_{i=0}^n\int_{F_i}X_n
=\int_FX_n
\le\int_FX_n^+
\le\Expn(X_n^+)$,}

\noindent as required.
}%end of proof of 275D

\cmmnt{\medskip

\noindent{\bf Remark} Note that in fact we have $\epsilon\hat\mu
F\le\int_FX_n$, where $F=\{\omega:X^*(\omega)\ge\epsilon\}$;  this is of
great importance in many applications.
}%end of comment

\leader{275E}{Up-crossings}\cmmnt{ The next lemma depends on the
notion of
`up-crossing'.}   Let $x_0,\ldots,x_n$ be any list of real numbers,
and $a<b$ in $\Bbb R$.   The {\bf number of up-crossings from $a$ to
$b$} in the list $x_0,\ldots,x_n$ is the number of pairs $(j,k)$ such
that $0\le j<k\le n$, $x_j\le a$, $x_k\ge b$ and $a<x_i<b$ for $j<i<k$.
\cmmnt{Note that this is also the largest $m$ such that $s_m<\infty$,
if we
write

\Centerline{$r_1=\inf\{i:i\le n,\,x_i\le a\}$,}

\Centerline{$s_1=\inf\{i:r_1<i\le n,\,x_i\ge b\}$,}

\Centerline{$r_2=\inf\{i:s_1<i\le n,\,x_i\le a\}$,}

\Centerline{$s_2=\inf\{i:r_2<i\le n,\,x_i\ge b\}$}

\noindent and so on, taking $\inf\emptyset=\infty$.
}%end of comment

\leader{275F}{Lemma} Let $(\Omega,\Sigma,\mu)$ be a probability space
and $\sequencen{X_n}$ a martingale on $\Omega$.   Suppose that $n\in\Bbb
N$ and that
$a<b$ in $\Bbb R$.   For each $\omega\in\bigcap_{i\le n}\dom X_i$, let
$U(\omega)$ be the number of up-crossings from $a$ to $b$ in the list
$X_0(\omega),\ldots,X_n(\omega)$.   Then

\Centerline{$\Expn(U)\le\Bover1{b-a}\Expn((X_n-X_0)^+)$,}

\noindent writing $(X_n-X_0)^+(\omega)=\max(0,X_n(\omega)-X_0(\omega))$
for $\omega\in\dom X_n\cap\dom X_0$.

\proof{ Each individual step in the proof is `elementary', but the
structure as a whole is non-trivial.

\medskip

{\bf (a)}  The following fact will be useful.   Suppose that
$x_0,\ldots,x_n$ are real numbers;  let $u$ be the number of
up-crossings from $a$ to $b$ in the list $x_0,\ldots,x_n$.   Set
$y_i=\max(x_i,a)$ for each $i$;  then $u$ is also the number of
up-crossings from $a$ to $b$ in the list $y_0,\ldots,y_n$.   For each
$k\le n$, set $c_k=1$ if there is a $j\le k$ such that $x_j\le a$ and
$x_i<b$ for $j\le i\le k$, $0$ otherwise.   Then

\Centerline{$(b-a)u\le\sum_{k=0}^{n-1}c_k(y_{k+1}-y_{k})$.}

\noindent\vthsp\Prf\ I induce on $m$ to show that (defining $r_m$, $s_m$
as in 275E)

\Centerline{$(b-a)m\le\sum_{k=0}^{s_m-1}c_k(y_{k+1}-y_{k})$}

\noindent whenever $m\le u$.   For $m=0$ (taking $s_0=-1$) we have
$0=0$.   For the inductive step to $m\ge 1$, we have
$s_{m-1}<r_{m}<s_m\le n$ (because I am supposing that $m\le u$), and
$c_k=0$ if $s_{m-1}\le k<r_{m}$, $c_k=1$ if $r_{m}\le k<s_m$.   So

$$\eqalignno{\sum_{k=0}^{s_{m}-1}c_k(y_{k+1}-y_{k})
&=\sum_{k=0}^{s_{m-1}-1}c_k(y_{k+1}-y_{k})
+\sum_{k=r_m}^{s_m-1}(y_{k+1}-y_k)\cr
&\ge(b-a)(m-1)+y_{s_m}-y_{r_m}\cr
\noalign{\noindent (by the inductive hypothesis)}
&\ge(b-a)m\cr}$$

\noindent (because $y_{s_m}\ge b$, $y_{r_m}=a$), and the induction
proceeds.


Accordingly

\Centerline{$\sum_{k=0}^{s_u-1}c_k(y_{k+1}-y_{k})\ge(b-a)u$.}

\noindent As for the sum $\sum_{k=s_u}^{n-1}c_k(y_{k+1}-y_k)$, we have
$c_k=0$ for $s_u\le k<r_{u+1}$, $c_k=1$ for $r_{u+1}\le k<s_{u+1}$, while
$s_{u+1}>n$, so if $n\le r_{u+1}$ we have

\Centerline{$\sum_{k=0}^{n-1}c_k(y_{k+1}-y_{k})
=\sum_{k=0}^{s_u-1}c_k(y_{k+1}-y_{k})\ge(b-a)u$,}

\noindent while if $n>r_{u+1}$ we have

$$\eqalign{\sum_{k=0}^{n-1}c_k(y_{k+1}-y_{k})
&=\sum_{k=0}^{s_u-1}c_k(y_{k+1}-y_{k})
+\sum_{k=r_{u+1}}^{n-1}y_{k+1}-y_k\cr
&\ge(b-a)u+y_n-y_{r_{u+1}}\cr
&\ge(b-a)u\cr}$$


\noindent because $y_n\ge a=y_{r_{u+1}}$.   Thus in both cases we have
the required result.\ \Qed

\medskip

{\bf (b)(i)} Now define

\Centerline{$Y_k(\omega)=\max(a,X_k(\omega))$ for $\omega\in\dom X_k$,}

\Centerline{$F_k=\{\omega:\omega\in\bigcap_{i\le k}\dom X_i,\,
\exists\,j\le k,\,X_j(\omega)\le a,\,X_i(\omega)<b$ if $j\le i\le k\}$}

\noindent for each $k\in\Bbb N$.   If $\sequencen{\Sigma_n}$ is a
non-decreasing sequence of $\sigma$-algebras to which $\sequencen{X_n}$
is adapted, then $F_k\in\Sigma_k$ (because
if $j\le k$ all the sets $\dom X_j$, $\{\omega:X_j(\omega)\le a\}$,
$\{\omega:X_j(\omega)<b\}$ belong to $\Sigma_j\subseteq\Sigma_k$).

\medskip

\quad{\bf (ii)} We find that $\int_FY_k\le\int_FY_{k+1}$ if
$F\in\Sigma_k$.   \Prf\ Set $G=\{\omega:X_k(\omega)>a\}\in\Sigma_k$.
Then

$$\eqalign{\int_FY_k
&=\int_{F\cap G}X_k+a\hat\mu(F\setminus G)\cr
&=\int_{F\cap G}X_{k+1}+a\hat\mu(F\setminus G)\cr
&\le\int_{F\cap G}Y_{k+1}+\int_{F\setminus G}Y_{k+1}
=\int_FY_{k+1}.\,\,\Qed\cr}$$

\medskip

\quad{\bf (iii)}
Consequently $\int_FY_{k+1}-Y_k\le\int Y_{k+1}-Y_k$ for every
$F\in\Sigma_k$.

\Centerline{\Prf\enskip $\int (Y_{k+1}-Y_k)-\int_F(Y_{k+1}-Y_k)
=\int_{\Omega\setminus F}Y_{k+1}-\int_{\Omega\setminus F}Y_k\ge 0$.
\Qed}

\medskip

{\bf (c)} Let $H$ be the conegligible set
$\dom U=\bigcap_{i\le n}\dom X_i\in\Sigma_n$.   We ought to check at
some point that $U$ is
$\Sigma_n$-measurable;  but this is clearly true, because all the
relevant sets $\{\omega:X_i(\omega)\le a\}$, $\{\omega:X_i(\omega)\ge
b\}$ belong to $\Sigma_n$.   For each $\omega\in H$, apply (a) to the
list $X_0(\omega),\ldots,X_n(\omega)$ to see that

\Centerline{$(b-a)U(\omega)\le\sum_{k=0}^{n-1}\chi F_k(\omega)
(Y_{k+1}(\omega)-Y_k(\omega))$.}

\noindent Because $H$ is conegligible, it follows that

$$\eqalignno{(b-a)\Expn(U)
&\le\sum_{k=0}^{n-1}\int_{F_k}Y_{k+1}-Y_k
\le\sum_{k=0}^{n-1}\int Y_{k+1}-Y_k\cr
\noalign{\noindent (using (b-iii))}
&=\Expn(Y_n-Y_0)
\le\Expn((X_n-X_0)^+)\cr}$$

\noindent because $Y_n-Y_0\le(X_n-X_0)^+$ everywhere  on $\dom
X_n\cap\dom X_0$.   This completes the proof.
}%end of proof of 275F


\leader{275G}{}\cmmnt{ We are now ready for the principal theorems of
this section.

\medskip

\noindent}{\bf Doob's Martingale Convergence Theorem} Let
$\sequencen{X_n}$ be a
martingale on a probability space $(\Omega,\Sigma,\mu)$, and suppose
that
$\sup_{n\in\Bbb N}\Expn(|X_n|)<\infty$.   Then
$\lim_{n\to\infty}X_n(\omega)$ is defined in $\Bbb R$ for almost every
$\omega$ in $\Omega$.

\proof{{\bf (a)} Set $H=\bigcap_{n\in\Bbb N}\dom X_n$, and for
$\omega\in H$ set

\Centerline{$Y(\omega)=\liminf_{n\to\infty}X_n(\omega)$,
\quad$Z(\omega)=\limsup_{n\to\infty}X_n(\omega)$,}

\noindent allowing $\pm\infty$ in
both cases.   But note that $Y\le\liminf_{n\to\infty}|X_n|$, so by
Fatou's Lemma $Y(\omega)<\infty$ for almost every $\omega$;  similarly
$Z(\omega)>-\infty$ for almost every $\omega$.   It will therefore be
enough if I can show that $Y\eae Z$, for then
$Y(\omega)=Z(\omega)\in\Bbb R$ for almost every $\omega$, and
$\sequencen{X_n(\omega)}$ will be convergent for almost every $\omega$.

\medskip

{\bf (b)} \Quer\ So suppose, if possible, that $Y$ and $Z$ are not equal
almost everywhere.   Of course both are $\hat\Sigma$-measurable, where
$(\Omega,\hat\Sigma,\hat\mu)$ is the completion of
$(\Omega,\Sigma,\mu)$, so we
must have

\Centerline{$\hat\mu\{\omega:\omega\in H,\,Y(\omega)<Z(\omega)\}>0$.}

\noindent    Accordingly there are rational numbers
$q$, $q'$ such that $q<q'$ and $\hat\mu G>0$, where

\Centerline{$G=\{\omega:\omega\in H,\,Y(\omega)<q<q'<Z(\omega)\}$.}

\noindent Now, for each $\omega\in H$ and $n\in\Bbb N$, let $U_n(\omega)$
be the number of up-crossings from $q$ to $q'$ in the list
$X_0(\omega),\ldots,
\ifdim\pagewidth>467pt\penalty-50\fi
X_n(\omega)$.   Then 275F tells us that

\Centerline{$\Expn(U_n)\le\Bover1{q'-q}\Expn((X_n-X_0)^+)
\le\Bover1{q'-q}\Expn(|X_n|+|X_0|)
\le\Bover{2M}{q'-q}$,}

\noindent if we write $M=\sup_{i\in\Bbb N}\Expn(|X_i|)$.   By B.Levi's
theorem, $U(\omega)=\sup_{n\in\Bbb N}U_n(\omega)<\infty$ for almost
every $\omega$.   On the other hand, if $\omega\in G$, then there are
arbitrarily large $j$, $k$ such that $X_j(\omega)<q$ and
$X_k(\omega)>q'$, so $U(\omega)=\infty$.   This means that $\hat\mu G$
must be $0$, contrary to the choice of $q$ and $q'$.   \Bang

\medskip

{\bf (c)} Thus we must in fact have $Y\eae Z$, and
$\sequencen{X_n(\omega)}$ is convergent for almost every $\omega$, as
claimed.
}%end of proof of 275G

\leader{275H}{Theorem}
Let $(\Omega,\Sigma,\mu)$ be a probability space, and
$\sequencen{\Sigma_n}$ a non-decreasing sequence of
$\sigma$-subalgebras of $\Sigma$.   Let $\sequencen{X_n}$ be a
martingale adapted to $\sequencen{\Sigma_n}$.   Then the following are
equiveridical:

\quad(i) there is a random variable $X$, of finite expectation, such
that $X_n$ is a conditional expectation of $X$ on $\Sigma_n$ for every
$n$;

\quad (ii) $\{X_n:n\in\Bbb N\}$ is uniformly integrable;

\quad (iii) $X_{\infty}(\omega)=\lim_{n\to\infty}X_n(\omega)$ is defined
in $\Bbb R$ for almost every $\omega$, and
$\Expn(|X_{\infty}|)=\lim_{n\to\infty}\Expn(|X_n|)<\infty$.

\proof{{\bf(i)$\Rightarrow$(ii)} By 246D, the set of all
conditional expectations of $X$ is uniformly integrable, so
$\{X_n:n\in\Bbb N\}$ is surely uniformly integrable.

\medskip

{\bf (ii)$\Rightarrow$(iii)} If $\{X_n:n\in\Bbb N\}$ is uniformly
integrable,  we surely have $\sup_{n\in\Bbb N}\Expn(|X_n|)<\infty$, so
275G tells us that $X_{\infty}$ is
defined almost everywhere.   By 246Ja, $X_{\infty}$ is integrable and
$\lim_{n\to\infty}\Expn(|X_n-X_{\infty}|)=0$.    Consequently
$\Expn(|X_{\infty}|)=\lim_{n\to\infty}\Expn(|X_n|)<\infty$.

\medskip

{\bf (iii)$\Rightarrow$(i)} Because
$\Expn(|X_{\infty}|)=\lim_{n\to\infty}\Expn(|X_n|)$,
$\lim_{n\to\infty}\Expn(|X_n-X_{\infty}|)=0$ (245H(a-ii)).     Now take
$n\in\Bbb N$ and $E\in\Sigma_n$.   Then

\Centerline{$\int_EX_n=\lim_{m\to\infty}\int_EX_m=\int_EX_{\infty}$.}

\noindent As $E$ is arbitrary, $X_n$ is a conditional expectation of
$X_{\infty}$ on $\Sigma_n$.
}%end of proof of 275H

\leader{275I}{Theorem} Let $(\Omega,\Sigma,\mu)$ be a probability space,
and $\sequencen{\Sigma_n}$ a non-decreasing sequence of
$\sigma$-subalgebras of $\Sigma$;  write $\Sigma_{\infty}$ for the
$\sigma$-algebra generated by $\bigcup_{n\in\Bbb N}\Sigma_n$.   Let $X$
be any real-valued random variable on $\Omega$ with finite expectation,
and for each $n\in\Bbb N$ let $X_n$ be a conditional expectation of $X$
on $\Sigma_n$.   Then $X_{\infty}(\omega)=\lim_{n\to\infty}X_n(\omega)$
is defined almost everywhere;
$\lim_{n\to\infty}\Expn(|X_{\infty}-X_n|)=0$, and $X_{\infty}$ is a
conditional expectation of $X$ on $\Sigma_{\infty}$.

\proof{ By 275G-275H, we know that $X_{\infty}$ is defined
almost everywhere, and, as remarked in the proof of 275H,
$\lim_{n\to\infty}\Expn(|X_{\infty}-X_n|)=0$.   To see that $X_{\infty}$
is a conditional expectation of $X$ on $\Sigma_{\infty}$, set

\Centerline{$\Cal A
=\{E:E\in\Sigma_{\infty},\,\int_EX_{\infty}=\int_EX\}$,
\quad$\Cal I=\bigcup_{n\in\Bbb N}\Sigma_n$.}

\noindent Now $\Cal I$ and $\Cal A$ satisfy the
conditions of the Monotone Class Theorem (136B).  \Prf\ {\bf
($\pmb{\alpha}$)} Of course
$\Omega\in\Cal I$ and $\Cal I$ is
closed under finite intersections, because $\sequencen{\Sigma_n}$ is a
non-decreasing sequence of $\sigma$-algebras;  in fact $\Cal I$ is a
subalgebra of $\Cal P\Omega$, and is closed under finite unions and
complements.   {\bf ($\pmb{\beta}$)} If $E\in\Cal I$, say
$E\in\Sigma_n$;  then

\Centerline{$\int_EX_{\infty}=\lim_{m\to\infty}\int_EX_m=\int_EX$,}

\noindent as in (iii)$\Rightarrow$(i) of 275H, so $E\in\Cal A$.   Thus
$\Cal I\subseteq\Cal A$.   {\bf ($\pmb{\gamma}$)} If $E$, $F\in\Cal A$
and $E\subseteq F$, then

\Centerline{$\int_{F\setminus E}X_{\infty}
=\int_FX_{\infty}-\int_EX_{\infty}
=\int_FX-\int_EX
=\int_{F\setminus E}X$,}

\noindent so $F\setminus E\in\Cal A$.   {\bf($\pmb{\delta}$)}
If $\sequencen{E_k}$ is a non-decreasing sequence in
$\Cal A$ with union $E$, then

\Centerline{$\int_{E}X_{\infty}
=\lim_{k\to\infty}\int_{E_k}X_{\infty}
=\lim_{k\to\infty}\int_{E_k}X
=\int_{E}X$,}

\noindent so $E\in\Cal A$.   Thus $\Cal A$ is a Dynkin class.\ \Qed

Consequently, by 136B, $\Cal A$ includes $\Sigma_{\infty}$;  that is,
$X_{\infty}$ is a conditional expectation of $X$ on $\Sigma_{\infty}$.
}%end of proof of 275I

\cmmnt{\medskip

\noindent{\bf Remark} I have written
`$\lim_{n\to\infty}\Expn(|X_n-X_{\infty}|)=0$';  but you may prefer to
say `$X^{\ssbullet}_{\infty}=\lim_{n\to\infty}X_n^{\ssbullet}$ in
$L^1(\mu)$', as in Chapter 24.

The importance of this theorem is such that you may be interested in a
proof based on 275D rather than 275E-275G;  see 275Xd.
}

\leader{*275J}{}\cmmnt{ As a corollary of this theorem I give an
important result, a kind of density theorem for product measures.

\medskip

\noindent}{\bf Proposition} Let $\sequencen{(\Omega_n,\Sigma_n,\mu_n)}$
be a sequence of probability spaces with product $(\Omega,\Sigma,\mu)$.
Let $X$ be a real-valued random variable on $\Omega$ with finite
expectation.   For each $n\in\Bbb N$ define $X_n$ by setting

\Centerline{$X_n(\pmb{\omega})
=\int X(\omega_0,\ldots,\omega_n,\xi_{n+1},\ldots)d(\xi_{n+1},\ldots)$}

\noindent wherever this is defined, where I write
`$\int\ldots d(\xi_{n+1},\ldots)$' to mean integration with respect to
the product measure $\lambda'_n$ on $\prod_{i\ge n+1}\Omega_i$.   Then
$X(\pmb{\omega})=\lim_{n\to\infty}X_n(\pmb{\omega})$ for almost every
$\pmb{\omega}=(\omega_0,\omega_1,\ldots)$ in $\Omega$, and
$\lim_{n\to\infty}\Expn(|X-X_n|)=0$.

\proof{ For each $n$, we can identify $\mu$ with the product of
$\lambda_n$ and $\lambda'_n$, where $\lambda_n$ is the product measure
on $\Omega_0\times\ldots\times\Omega_n$ (254N).   So 253H tells us that
$X_n$ is a conditional expectation of $X$ on the $\sigma$-algebra
$\Lambda_n=\{E\times\prod_{i>n}\Omega_i:E\in\dom\lambda_n\}$.   Since
(by 254N again) we can think of $\lambda_{n+1}$ as the product of
$\lambda_n$ and $\mu_{n+1}$, $\Lambda_n\subseteq\Lambda_{n+1}$ for each
$n$.   So 275I tells us that $\sequencen{X_n}$ converges almost
everywhere to a conditional expectation $X_{\infty}$ of $X$ on the
$\sigma$-algebra $\Lambda_{\infty}$ generated by
$\bigcup_{n\in\Bbb N}\Lambda_n$.   Now $\Lambda_{\infty}\subseteq\Sigma$
and also $\Tensorhat_{n\in\Bbb N}\Sigma_n\subseteq\Lambda_{\infty}$, so
every member of $\Sigma$ is sandwiched between two members of
$\Lambda_{\infty}$ of the same measure (254Ff), and $X_{\infty}$ must be
equal to $X$ almost everywhere.   Moreover, 275I also tells us that

\Centerline{$\lim_{n\to\infty}\Expn(|X-X_n|)
=\lim_{n\to\infty}\Expn(|X_{\infty}-X_n|)=0$,}

\noindent as required.
}%end of proof of 275J

\leader{275K}{Reverse \dvrocolon{martingales}}\cmmnt{ We have a result
corresponding to 275I for {\it decreasing} sequences of
$\sigma$-algebras.   While this is used less often than
275G-275I, %275G 275H 275I
it does have very important applications.

\medskip

\noindent}{\bf Theorem} Let $(\Omega,\Sigma,\mu)$ be a probability
space, and $\sequencen{\Sigma_n}$ a non-increasing sequence of
$\sigma$-subalgebras of $\Sigma$, with intersection $\Sigma_{\infty}$.
Let $X$ be any real-valued random variable with finite expectation, and
for each $n\in\Bbb N$ let $X_n$ be a conditional expectation of $X$ on
$\Sigma_n$.   Then $X_{\infty}=\lim_{n\to\infty}X_n$ is defined almost
everywhere and is a conditional expectation of $X$ on $\Sigma_{\infty}$.

\proof{{\bf (a)} Set $H=\bigcap_{n\in\Bbb N}\dom X_n$, so that $H$ is
conegligible.   For $n\in\Bbb N$, $a<b$ in $\Bbb R$, and $\omega\in H$,
write $U_{abn}(\omega)$ for the number of up-crossings from $a$ to $b$
in the list $X_n(\omega),X_{n-1}(\omega),\ldots,X_0(\omega)$ (275E).
Then

$$\eqalignno{\Expn(U_{abn})
&\le\Bover1{b-a}\Expn((X_0-X_n)^+)\cr
\displaycause{275F}
&\le\Bover1{b-a}\Expn(|X_0|+|X_n|)
\le\Bover2{b-a}\Expn(|X_0|)<\infty.\cr}$$

\noindent So $\lim_{n\to\infty}U_{abn}(\omega)$ is finite for almost
every $\omega$.   But this means that

\Centerline{$\{\omega:\liminf_{n\to\infty}X_n(\omega)<a,\,
  \limsup_{n\to\infty}X_n(\omega)>b\}$}

\noindent is negligible.   As $a$ and $b$ are arbitrary,
$\sequencen{X_n}$ is convergent a.e., just as in 275G.   Set
$X_{\infty}(\omega)=\lim_{n\to\infty}X_n(\omega)$ whenever this is
defined in $\Bbb R$.

\medskip

{\bf (b)} By 246D, $\{X_n:n\in\Bbb N\}$ is uniformly integrable, so
$\Expn(|X_n-X_{\infty}|)\to 0$ as $n\to\infty$ (246Ja), and

\Centerline{$\int_EX_{\infty}=\lim_{n\to\infty}\int_EX_n=\int_EX_0$}

\noindent for every $E\in\Sigma_{\infty}$.

\medskip

{\bf (c)} Now there is a conegligible set $G\in\Sigma_{\infty}$ such
that $G\subseteq\dom X_{\infty}$ and $X_{\infty}\restr G$ is
$\Sigma_{\infty}$-measurable.   \Prf\ For each $n\in\Bbb N$, there is a
conegligible set $G_n\in\Sigma_n$ such that $G_n\subseteq\dom X_n$ and
$X_n\restr G_n$ is $\Sigma_n$-measurable.   Set
$G'=\bigcup_{n\in\Bbb N}\bigcap_{m\ge n}G_m$;  then, for any
$r\in\Bbb N$, $G'=\bigcup_{n\ge r}\bigcap_{m\ge n}G_m$ belongs to
$\Sigma_r$, so $G'\in\Sigma_{\infty}$, while of course $G'$ is
conegligible.   For $n\in\Bbb N$, set $X'_n(\omega)=X_n(\omega)$ for
$\omega\in G_n$, $0$ for $\omega\in\Omega\setminus G_n$;  then for
$\omega\in G'$,
$\lim_{n\to\infty}X'_n(\omega)=\lim_{n\to\infty}X_n(\omega)$ if either
is defined in $\Bbb R$.   Writing $X'_{\infty}=\lim_{n\to\infty}X'_n$
whenever this is defined in $\Bbb R$, 121F and 121H tell us that
$X'_{\infty}$ is $\Sigma_r$-measurable and $\dom X'_{\infty}\in\Sigma_r$
for every $r\in\Bbb N$, so that $G''=\dom X'_{\infty}$ belongs to
$\Sigma_{\infty}$ and $X'_{\infty}$ is $\Sigma_{\infty}$-measurable.
We also know, from (a), that $G''$ is conegligible.   So setting
$G=G'\cap G''$ we have the result.\ \Qed

Thus $X_{\infty}$ is a conditional expectation of $X$ on
$\Sigma_{\infty}$.
}%end of proof of 275K

\leader{275L}{Stopping\dvro{ times: }{ times}}\cmmnt{ In a sense, the
main work of this section
is over;  I have no room for any more theorems of importance comparable
to 275G-275I.   However, it would be wrong to leave this chapter without
briefly describing one of the most fruitful ideas of the subject.

\medskip

\noindent}{\bf Definition} Let $(\Omega,\Sigma,\mu)$ be a probability
space, with completion $(\Omega,\hat\Sigma,\hat\mu)$, and
$\sequencen{\Sigma_n}$ a non-decreasing sequence of
$\sigma$-subalgebras of $\hat\Sigma$.   A {\bf stopping time adapted to
$\sequencen{\Sigma_n}$}\cmmnt{ (also called `{\bf optional time}',
`{\bf Markov time}')} is a function $\tau$ from $\Omega$ to
$\Bbb N\cup\{\infty\}$ such that
$\{\omega:\tau(\omega)\le n\}\in\Sigma_n$ for every $n\in\Bbb N$.

\cmmnt{\medskip

\noindent{\bf Remark} Of course the condition

\Centerline{$\{\omega:\tau(\omega)\le n\}\in\Sigma_n$ for every
$n\in\Bbb N$}

\noindent can be replaced by the equivalent condition

\Centerline{$\{\omega:\tau(\omega)=n\}\in\Sigma_n$
for every $n\in\Bbb N$.}

\noindent I give priority to the former expression because it is more
appropriate to other index sets (see 275Cc).
}%end of comment

\leader{275M}{Examples (a)} If $\sequencen{X_n}$ is a martingale adapted
to a sequence $\sequencen{\Sigma_n}$ of $\sigma$-algebras, and ${H_n}$
is a Borel subset of $\BbbR^{n+1}$ for each $n$, then we have a
stopping time $\tau$ adapted to $\sequencen{\Sigma_n}$ defined by the
formula

\Centerline{$\tau(\omega)
=\inf\{n:\omega\in\bigcap_{i\le n}\dom X_i,\,
  (X_0(\omega),\ldots,X_n(\omega))\in H_n\}$,}

\noindent setting $\inf\emptyset=\infty$\cmmnt{ as usual}.
\cmmnt{(For by 121Ka the
set $E_n=\{\omega:(X_0(\omega),\ldots,X_n(\omega))\in H_n\}$ belongs to
$\Sigma_n$ for each $n$, and
$\{\omega:\tau(\omega)\le n\}=\bigcup_{i\le n}E_i$.)}   In particular,
\cmmnt{for instance,}  the formulae

\Centerline{$\inf\{n:X_n(\omega)\ge a\}$, \quad
$\inf\{n:|X_n(\omega)|> a\}$}

\noindent define stopping times.

\header{275Mb}{\bf (b)} Any constant function
$\tau:\Omega\to\Bbb N\cup\{\infty\}$ is a stopping time.   If $\tau$,
$\tau'$ are two
stopping times adapted to the same sequence $\sequencen{\Sigma_n}$ of
$\sigma$-algebras, then $\tau\wedge\tau'$ is a stopping time adapted to
$\sequencen{\Sigma_n}$, setting
$(\tau\wedge\tau')(\omega)=\min(\tau(\omega),\tau'(\omega))$ for
$\omega\in\Omega$\prooflet{, because

\Centerline{$\{\omega:(\tau\wedge\tau')(\omega)\le n\}
=\{\omega:\tau(\omega)\le n\}\cup\{\omega:\tau'(\omega)\le n\}
\in\Sigma_n$}

\noindent for every $n\in\Bbb N$}.

\leader{275N}{Lemma} Let $(\Omega,\Sigma,\mu)$ be a complete probability
space, and $\sequencen{\Sigma_n}$ a non-decreasing sequence of
$\sigma$-subalgebras of $\Sigma$.   Suppose that $\tau$ and $\tau'$ are
stopping times on $\Omega$, and $\sequencen{X_n}$ a martingale, all
adapted to $\sequencen{\Sigma_n}$.

(a) The family

\Centerline{$\tilde\Sigma_{\tau}
=\{E:E\in\Sigma,\,E\cap\{\omega:\tau(\omega)\le n\}\in\Sigma_n$ for
every $n\in\Bbb N\}$}

\noindent is a $\sigma$-subalgebra of $\Sigma$.

(b) If $\tau(\omega)\le\tau'(\omega)$ for every
$\omega$, then $\tilde\Sigma_{\tau}\subseteq\tilde\Sigma_{\tau'}$.

(c) Now suppose that $\tau$ is finite almost everywhere.   Set

\Centerline{$\tilde X_{\tau}(\omega)=X_{\tau(\omega)}(\omega)$}

\noindent whenever $\tau(\omega)<\infty$ and
$\omega\in\dom X_{\tau(\omega)}$.   Then
$\dom\tilde X_{\tau}\in\tilde\Sigma_{\tau}$ and $\tilde X_{\tau}$ is
$\tilde\Sigma_{\tau}$-measurable.

(d) If $\tau$ is essentially bounded, that is, there is some
$m\in\Bbb N$ such that $\tau\le m$ almost everywhere, then
$\Expn(\tilde X_{\tau})$ exists and is equal to $\Expn(X_0)$.

(e) If $\tau\le\tau'$ almost everywhere, and $\tau'$ is essentially
bounded, then $\tilde X_{\tau}$ is a conditional expectation of
$\tilde X_{\tau'}$ on $\tilde\Sigma_{\tau}$.

\proof{{\bf (a)}  This is elementary.   Write
$H_n=\{\omega:\tau(\omega)\le n\}$ for each $n\in\Bbb N$.   The empty
set belongs to $\tilde\Sigma_{\tau}$ because it belongs to $\Sigma_n$
for every $n$.
If $E\in\tilde\Sigma_{\tau}$, then

\Centerline{$(\Omega\setminus E)\cap H_n=H_n\setminus(E\cap
H_n)\in\Sigma_n$}

\noindent because $H_n\in\Sigma_n$;  this is true for for every $n$, so
$X\setminus E\in\tilde\Sigma_{\tau}$.   If $\sequence{k}{E_k}$ is any
sequence in $\tilde\Sigma_{\tau}$ then

\Centerline{$(\bigcup_{k\in\Bbb N}E_k)\cap H_n=\bigcup_{k\in\Bbb
N}E_k\cap H_n\in\Sigma_n$}

\noindent for every $n$, so $\bigcup_{k\in\Bbb
N}E_k\in\tilde\Sigma_{\tau}$.

\medskip

{\bf (b)} If $E\in\tilde\Sigma_{\tau}$ then of course $E\in\Sigma$,
and if $n\in\Bbb N$ then $\{\omega:\tau'(\omega)\le
n\}\subseteq\{\omega:\tau(\omega)\le n\}$, so that

\Centerline{$E\cap\{\omega:\tau'(\omega)\le n\}
=E\cap\{\omega:\tau(\omega)\le n\}\cap\{\omega:\tau'(\omega)\le
n\}$}

\noindent belongs to $\Sigma_n$;  as $n$ is arbitrary,
$E\in\tilde\Sigma_{\tau'}$.

\medskip

{\bf (c)} Set $H_n=\{\omega:\tau(\omega)\le n\}$ for each $n\in\Bbb N$.
For any $a\in\Bbb R$,

$$\eqalign{H_n\cap\{\omega:\omega\in
&\dom\tilde X_{\tau},\,\tilde X_{\tau}(\omega)\le a\}\cr
&=\bigcup_{k\le n}\{\omega:\tau(\omega)=k,\,\omega\in\dom X_k,
  \,X_k(\omega)\le a\}
\in\Sigma_n.\cr}$$

\noindent As $n$ is arbitrary,

\Centerline{$G_a=\{\omega:\omega\in\dom\tilde X_{\tau},\,
\tilde X_{\tau}(\omega)\le a\}\in\tilde\Sigma_{\tau}$.}

\noindent As $a$ is arbitrary, $\dom\tilde X_{\tau}=\bigcup_{m\in\Bbb
N}G_m\in\tilde\Sigma_{\tau}$ and $\tilde X_{\tau}$ is
$\tilde\Sigma_{\tau}$-measurable.

\medskip

{\bf (d)} Set $H_k=\{\omega:\tau(\omega)=k\}$ for $k\le m$.   Then
$\bigcup_{k\le m}H_k$ is conegligible, so

\Centerline{$\Expn(\tilde X_{\tau})
=\sum_{k=0}^m\int_{H_k}X_k
=\sum_{k=0}^m\int_{H_k}X_m
=\int_{\Omega}X_m
=\int_{\Omega}X_0$.}

\medskip

{\bf (e)} Suppose $\tau'\le n$ almost everywhere.   Set
$H_k=\{\omega:\tau(\omega)=k\}$,
$H'_k=\{\omega:\tau'(\omega)=k\}$ for each $k$;  then both
$\langle H_k\rangle_{k\le n}$ and $\langle H'_k\rangle_{k\le n}$ are
partitions of conegligible subsets of $X$.
Now suppose that $E\in\tilde\Sigma_{\tau}$.   Then

\Centerline{$\int_E\tilde X_{\tau}
=\sum_{k=0}^n\int_{E\cap H_k}\tilde X_{\tau}
=\sum_{k=0}^n\int_{E\cap H_k}X_k
=\sum_{k=0}^n\int_{E\cap H_k}X_n
=\int_EX_n$}

\noindent because $E\cap H_k\in\Sigma_k$ for every $k$.   By (b),
$E\in\tilde\Sigma_{\tau'}$, so we also have
$\int_E\tilde X_{\tau'}=\int_EX_n$.   Thus
$\int_E\tilde X_{\tau}=\int_E\tilde X_{\tau'}$ for every
$E\in\tilde\Sigma_{\tau}$, as claimed.
}%end of proof of 275N

\leader{275O}{Proposition} Let $\sequencen{X_n}$ be a martingale and
$\tau$ a stopping time, both adapted to the same sequence
$\sequencen{\Sigma_n}$ of
$\sigma$-algebras.   For each $n$, set $(\tau\wedge
n)(\omega)=\min(\tau(\omega),n)$ for $\omega\in\Omega$;  then
$\tau\wedge n$ is a stopping time, and $\sequencen{\tilde X_{\tau\wedge
n}}$ is a martingale
adapted to $\sequencen{\tilde\Sigma_{\tau\wedge n}}$, defining
$\tilde X_{\tau\wedge n}$ and $\tilde\Sigma_{\tau\wedge n}$ as in 275N.

\proof{ As remarked in 275Mb, each $\tau\wedge n$ is a
stopping time.   If $m\le n$, then $\tilde\Sigma_{\tau\wedge
m}\subseteq\tilde\Sigma_{\tau\wedge n}$ by 275Nb.   Each
$\tilde X_{\tau\wedge m}$ is
$\tilde\Sigma_{\tau\wedge m}$-measurable, with domain belonging to
$\tilde\Sigma_{\tau\wedge m}$,  by 275Nc, and has finite expectation, by
275Nd;  finally, if $m\le n$, then $\tilde X_{\tau\wedge m}$ is a
conditional expectation of
$\tilde X_{\tau\wedge n}$ on $\tilde\Sigma_{\tau\wedge m}$, by 275Ne.
}%end of proof of 275O

\leader{275P}{Corollary} Suppose that $(\Omega,\Sigma,\mu)$ is a
probability space and $\sequencen{X_n}$ is a martingale on $\Omega$ such
that $W=\sup_{n\in\Bbb N}|X_{n+1}-X_n|$ is finite almost everywhere and
has finite expectation.   Then for almost every $\omega\in\Omega$,
either $\lim_{n\to\infty}X_n(\omega)$ exists in $\Bbb R$ or
$\sup_{n\in\Bbb N}X_n(\omega)=\infty$ and $\inf_{n\in\Bbb
N}X_n(\omega)=-\infty$.

\proof{ Let $\sequencen{\Sigma_n}$ be a non-decreasing sequence of
$\sigma$-algebras to which $\sequencen{X_n}$ is adapted.    Let $H$ be
the conegligible set $\bigcap_{n\in\Bbb N}\dom
X_n\cap\{\omega:W(\omega)<\infty\}$.   For each $m\in\Bbb N$, set

\Centerline{$\tau_m(\omega)=\inf\{n:\omega\in\dom
X_n,\,X_n(\omega)>m\}$.}

\noindent As in 275Ma, $\tau_m$ is a stopping time adapted to
$\sequencen{\Sigma_n}$.   Set

\Centerline{$Y_{mn}=\tilde X_{\tau_m\wedge n}$,}

\noindent defined as in 275O, so that $\sequencen{Y_{mn}}$ is a
martingale.   If
$\omega\in H$, then either $\tau_m(\omega)>n$ and

\Centerline{$Y_{mn}(\omega)=X_n(\omega)\le m$,}

\noindent or $0<\tau_m(\omega)\le n$ and

\Centerline{$Y_{mn}(\omega)=X_{\tau_m(\omega)}(\omega)
\le W(\omega)+X_{\tau_m(\omega)-1}(\omega)\le W(\omega)+m$,}

\noindent or $\tau_m(\omega)=0$ and

\Centerline{$Y_{mn}(\omega)=X_0(\omega)$.}

\noindent Thus

\Centerline{$Y_{mn}(\omega)\le|X_0(\omega)|+W(\omega)+m$}

\noindent for every $\omega\in H$, and

\Centerline{$|Y_{mn}(\omega)|=2\max(0,Y_{mn}(\omega))-Y_{mn}(\omega)
\le 2(|X_0(\omega)|+W(\omega)+m)-Y_{mn}(\omega)$,}

\Centerline{$\Expn(|Y_{mn}|)\le 2\Expn(|X_0|)+2\Expn(W)+2m-\Expn(Y_{mn})
= 2\Expn(|X_0|)+2\Expn(W)+2m-\Expn(X_0)$}

\noindent by 275Nd.   As this is true for every $n\in\Bbb N$,
$\sup_{n\in\Bbb N}\Expn(|Y_{mn}|)<\infty$, and $\lim_{n\to\infty}Y_{mn}$
is defined in $\Bbb R$ almost everywhere, by Doob's Martingale
Convergence Theorem (275G).   Let $F_m$ be the conegligible set on which
$\sequencen{Y_{mn}}$ converges.
Set $H^*=H\cap\bigcap_{m\in\Bbb N}F_m$, so that $H^*$ is conegligible.

Now consider

\Centerline{$E=\{\omega:\omega\in H^*,\,\sup_{n\in\Bbb
N}X_n(\omega)<\infty\}$.}

\noindent For any $\omega\in E$, there must be an $m\in\Bbb N$ such that
$\sup_{n\in\Bbb N}X_n(\omega)\le m$.   Now this means that
$Y_{mn}(\omega)=X_n(\omega)$ for every $n$, and as $\omega\in F_m$ we
have

\Centerline{$\lim_{n\to\infty}X_n(\omega)
=\lim_{n\to\infty}Y_{mn}(\omega)\in\Bbb R$.}

\noindent This means that $\sequencen{X_n(\omega)}$ is convergent for
almost every $\omega$ such that $\{X_n(\omega):n\in\Bbb N\}$ is bounded
above.

Similarly, $\sequencen{X_n(\omega)}$ is convergent for almost every
$\omega$ such that $\{X_n(\omega):n\in\Bbb N\}$ is bounded below, which
completes the proof.
}%end of proof of 275P


\exercises{
\leader{275X}{Basic exercises $\pmb{>}$(a)}
%\sqheader 275Xa
Let $\sequencen{X_n}$ be an
independent sequence of random variables with zero expectation and finite
variance.   Set $s_n=(\sum_{i=0}^n\Var(X_i))^{1/2}$,
$Y_n=(X_0+\ldots+X_n)^2-s_n^2$ for each $n$.   Show that
$\sequencen{Y_n}$ is a martingale.
%275B

\sqheader 275Xb Let $\sequencen{X_n}$ be a martingale.   Show that for
any $\epsilon>0$, $\Pr(\sup_{n\in\Bbb N}|X_n|)\ge\epsilon)
\le\bover1\epsilon\sup_{n\in\Bbb N}\Expn(|X_n|)$.
%275D

\spheader 275Xc {\bf P\'olya's urn scheme} Imagine a box containing
red and white balls.   At each move, a ball is drawn at random from the
box and replaced together with another of the same colour.  (i) Writing
$R_n$, $W_n$ for the numbers of red and white balls after the $n$th move
and $X_n=R_n/(R_n+W_n)$,
show that $\sequencen{X_n}$ is a martingale.   (ii) Starting from
$R_0=W_0=1$, find the distribution of $(R_n,W_n)$ for each $n$.
(iii) Show that $X=\lim_{n\to\infty}X_n$ is defined almost everywhere,
and find its distribution when $R_0=W_0=1$.   (See {\smc Feller 66} for
a discussion of other starting values.)
%275G

\sqheader 275Xd Let $(\Omega,\Sigma,\mu)$ be a probability space, and
$\sequencen{\Sigma_n}$ a non-decreasing sequence of $\sigma$-subalgebras
of $\Sigma$;  for each $n\in\Bbb N$ let $P_n:L^1\to L^1$ be the
conditional expectation operator corresponding to $\Sigma_n$, where
$L^1=L^1(\mu)$ (242J).   (i) Show that
$V=\{u:u\in L^1,\,\lim_{n\to\infty}\|P_nu-u\|_1=0\}$ is a
$\|\,\|_1$-closed linear subspace of $L^1$.   (ii) Show that
$\{E:E\in\Sigma,\,\chi E^{\ssbullet}\in V\}$ is a Dynkin class including
$\bigcup_{n\in\Bbb N}\Sigma_n$, so includes the $\sigma$-algebra
$\Sigma_{\infty}$ generated by $\bigcup_{n\in\Bbb N}\Sigma_n$.   (iii)
Show that if $u\in L^1$ then
$v=\sup_{n\in\Bbb N}P_n|u|$ is defined in $L^1$ and is of the form
$W^{\ssbullet}$ where $\Pr(W\ge\epsilon)\le\bover1{\epsilon}\|u\|_1$ for
every $\epsilon>0$.   \Hint{275D.}   (iv) Show that if $X$ is a
$\Sigma_{\infty}$-measurable random variable with finite expectation,
and for each $n\in\Bbb N\,\,X_n$ is a conditional expectation of $X$ on
$\Sigma_n$, then $X^{\ssbullet}\in V$ and $X\eae\lim_{n\to\infty}X_n$.
\Hint{apply (iii) to $u=(X-X_m)^{\ssbullet}$ for large $m$.}
%275I

\spheader 275Xe Let $(\Omega,\Sigma,\mu)$ be a probability space,
$\sequencen{\Sigma_n}$ a non-decreasing sequence of $\sigma$-subalgebras
of $\Sigma$, and $\Sigma_{\infty}$ the $\sigma$-algebra generated by
$\bigcup_{n\in\Bbb N}\Sigma_n$.   For each $n\in\Bbb N\cup\{\infty\}$
let $P_n:L^1\to L^1$ be the conditional expectation operator
corresponding to $\Sigma_n$, where $L^1=L^1(\mu)$.   Show that
$\lim_{n\to\infty}\|P_nu-P_{\infty}u\|_p=0$ whenever $p\in\coint{1,\infty}$ and
$u\in L^p(\mu)$.
\Hint{275Xd, 233J/242K, 246Xg.}
%275Xd, 275I

\spheader 275Xf Let $\sequencen{X_n}$ be a martingale, and
suppose that $p\in\ooint{1,\infty}$ is such that
$\sup_{n\in\Bbb N}\|X_n\|_p<\infty$.   Show that
$X=\lim_{n\to\infty}X_n$ is defined almost everywhere and that
$\lim_{n\to\infty}\|X_n-X\|_p=0$.
%275Xe, 275H, 275I

\sqheader 275Xg Let $(\Omega,\Sigma,\mu)$ be $[0,1]$ with
Lebesgue measure.   For each $n\in\Bbb N$ let $\Sigma_n$ be the finite
subalgebra of $\Sigma$ generated by intervals of the type $[0,2^{-n}r]$
for $r\le 2^{-n}$.   Use 275I to show that for any integrable
$X:[0,1]\to\Bbb R$ we must have
$X(t)=\lim_{n\to\infty}2^n\int_{I_n(t)}X$ for almost every
$t\in\coint{0,1}$, where $I_n(t)$ is
the interval of the form $\coint{2^{-n}r,2^{-n}(r+1)}$ containing $t$.
Compare this result with 223A and 261Yd.
%275I

\spheader 275Xh In 275K, show that
$\lim_{n\to\infty}\|X_n-X_{\infty}\|_p=0$ for any $p\in\coint{1,\infty}$
such that $\|X_0\|_p$ is finite.   (Compare 275Xe.)
%275K

\spheader 275Xi\dvAnew{2012} Let $(\Omega,\Sigma,\mu)$ be a probability
space, with completion $(\Omega,\hat\Sigma,\hat\mu)$, and
$\sequencen{\Sigma_n}$ a non-decreasing sequence of
$\sigma$-subalgebras of $\hat\Sigma$.   Show that if $\sequence{i}{\tau_i}$
is a sequence of stopping times adapted to $\sequencen{\Sigma_n}$, and we
set $\tau(\omega)=\sup_{i\in\Bbb N}\tau_i(\omega)$ for $\omega\in\Omega$,
then $\tau$ is a stopping time adapted to $\sequencen{\Sigma_n}$.
%275M

\spheader 275Xj Let $(\Omega,\Sigma,\mu)$ be a probability
space, with completion $(\Omega,\hat\Sigma,\hat\mu)$, and
$\sequencen{\Sigma_n}$ a non-decreasing sequence of
$\sigma$-subalgebras of $\hat\Sigma$.   Let $\sequencen{X_n}$ be a
uniformly integrable martingale adapted to $\Sigma_n$, and set
$X_{\infty}=\lim_{n\to\infty}X_n$.   Let $\tau$ be a stopping time
adapted to $\sequencen{\Sigma_n}$, and set
$\tilde X_{\tau}(\omega)=X_{\tau(\omega)}(\omega)$ whenever
$\omega\in\dom X_{\tau(\omega)}$,
allowing $\infty$ as a value of $\tau(\omega)$.   Show that
$\tilde X_{\tau}$
is a conditional expectation of $X_{\infty}$ on $\tilde\Sigma_{\tau}$,
as defined in 275N.
%275N

\spheader 275Xk Let $(\Omega,\Sigma,\mu)$ be a probability
space, with completion $(\Omega,\hat\Sigma,\hat\mu)$, and
$\sequencen{\Sigma_n}$ a non-decreasing sequence of
$\sigma$-subalgebras of $\hat\Sigma$.   Let $\sequencen{X_n}$ be a
martingale and $\tau$ a stopping time, both adapted to
$\sequencen{\Sigma_n}$.   Suppose that
$\sup_{n\in\Bbb N}\Expn(|X_n|)<\infty$ and that $\tau$ is finite almost
everywhere.
Show that $\tilde X_{\tau}$, as defined in 275Nc, has finite
expectation, but
that $\Expn(\tilde X_{\tau})$ need not be equal to $\Expn(X_0)$.
%275N

\spheader 275Xl(i)\dvAnew{2014} Show that if $\sequencen{X_n}$ is a martingale
such that $\sup_{n\in\Bbb N}\Expn(|X_n|)$ is finite and $\sequencen{X_n}$ is
convergent in measure, then $\sequencen{X_n}$ is convergent a.e.
(ii) Find a martingale $\sequencen{X_n}$ such that
$\sequencen{X_{2n}}\to 0$ a.e.\ but $|X_{2n+1}|\ge 1$ a.e.\ for every
$n\in\Bbb N$.   (iii) Find a martingale which converges in measure but is
not convergent a.e.   
%275D+  

\leader{275Y}{Further exercises (a)}%
%\spheader 275Ya
\dvAnew{2012} Let $(\Omega,\Sigma,\mu)$ be a probability space,
$\sequencen{\Sigma_n}$ an independent sequence of $\sigma$-subalgebras
of $\Sigma$, and $X$ a random variable on $\Omega$ with finite variance.
Let $X_n$ be a conditional expectation of $X$ on $\Sigma_n$ for each
$n$.   Show that $\lim_{n\to\infty}X_n=\Expn(X)$ almost everywhere.
\Hint{consider $\sum_{n=0}^{\infty}\Var(X_n)$.}
%-

\spheader 275Yb
Let $(\Omega,\Sigma,\mu)$ be a complete probability space,
$\sequencen{\Sigma_n}$ a non-decreasing sequence of
$\sigma$-subalgebras of $\Sigma$ all containing every negligible set,
and $\sequencen{X_n}$ a martingale adapted to $\sequencen{\Sigma_n}$.
Let $\nu$ be another probability measure with domain $\Sigma$ which is
absolutely continuous with respect to $\mu$, with Radon-Nikod\'ym
derivative $Z$.   For each $n\in\Bbb N$ let $Z_n$ be a conditional
expectation of $Z$ on $\Sigma_n$ (with respect to the measure $\mu$).
(i) Show that $Z_n$ is a Radon-Nikod\'ym derivative of
$\nu\restr\Sigma_n$ with respect to $\mu\restr\Sigma_n$, for each
$n\in\Bbb N$.   (ii) Defining $X_n/Z_n$ as in 121E, so that its domain is
$\{\omega:\omega\in\dom X_n\cap\dom Z_n$, $Z_n(\omega)\ne 0\}$,
show that $\sequencen{X_n/Z_n}$ is a martingale with respect to
the measure $\nu$.
%275B

\spheader 275Yc Combine the ideas of 275Cc with those of
275Cd-275Ce to describe a notion of `martingale indexed by $I$', where
$I$ is an arbitrary partially ordered set.
%275C

\spheader 275Yd\dvAformerly{2{}75Yc}
Let $\sequence{k}{X_k}$ be a martingale on a complete
probability space $(\Omega,\Sigma,\mu)$, and fix
$n\in\Bbb N$.   Set $X^*=\max(|X_0|,\ldots,\discretionary{}{}{}|X_n|)$.
Let $p\in\ooint{1,\infty}$.
Show that $\|X^*\|_p\le\Bover{p}{p-1}\|X_n\|_p$.   ({\it Hint\/}:  set
$F_t=\{\omega:X^*(\omega)\ge t\}$.   Show that
$t\mu F_t\le\int_{F_t}|X_n|$.   Using Fubini's
theorem on $\Omega\times\coint{0,\infty}$ and on
$\Omega\times\coint{0,\infty}\times\coint{0,\infty}$, show that

\Centerline{$\Expn((X^*)^p)=p\int_0^{\infty}t^{p-1}\mu F_tdt$,}

\Centerline{$\int_0^{\infty}t^{p-2}\int_{F_t}|X_n|dt
=\Bover1{p-1}\Expn(|X_n|\times(X^*)^{p-1})$,}

\Centerline{$\Expn(|X_n|\times(X^*)^{p-1})
\le\|X_n\|_p\|X^*\|_p^{p-1}$.}

\noindent Compare 286A below.)
%275D

\spheader 275Ye\dvArevised{2012}(i)
Show that if $a$, $b\ge 0$ then
$a\ln^+b\le a\ln^+a+\Bover{b}e$, where $\ln^+t=0$ if $t\le 1$,
$\ln t$ if $t\ge 1$.
(ii) Let $(\Omega,\Sigma,\mu)$ be a
complete probability space and $X$, $Y$
non-negative random variables on $\Omega$ such that
$t\mu F_t\le\int_{F_t}X$ for every $t\ge 0$, where
$F_t=\{\omega:Y(\omega)\ge t\}$.   Show that
$\int_{F_1}Y\le\int_{F_1}X\times\ln^+Y$, and hence that
$\Expn(Y)\le\Bover{e}{e-1}(1+\Expn(X\times\ln^+X))$.   (iii) Show that
if $\sequencen{X_n}$ is a martingale on $\Omega$, $n\in\Bbb N$ and
$X^*=\sup_{i\le n}|X_i|$, then
$\Expn(X^*)\le\Bover{e}{e-1}(1+\Expn(|X_n|\times\ln^+|X_n|))$.
%275Yd, 275D {\smc Doob 53}

\spheader 275Yf Let $(\Omega,\Sigma,\mu)$ be a probability space
and $\langle\Sigma_i\rangle_{i\in I}$ a countable family  of
$\sigma$-subalgebras of $\Sigma$ such that for any $i$, $j\in I$ either
$\Sigma_i\subseteq\Sigma_j$ or $\Sigma_j\subseteq\Sigma_i$.   Let $X$ be
a real-valued random variable on $\Omega$ such that $\|X\|_p<\infty$,
where $1<p<\infty$, and suppose that $X_i$ is a conditional expectation
of $X$ on $\Sigma_i$ for each $i\in I$.   Show that
$\|\sup_{i\in I}|X_i|\|_p\le\Bover{p}{p-1}\|X\|_p$.
%275Yd, 275D

\spheader 275Yg Let $(\Omega,\Sigma,\mu)$ be a probability
space, with completion $(\Omega,\hat\Sigma,\hat\mu)$, and let
$\sequencen{\Sigma_n}$ be a non-decreasing sequence of
$\sigma$-subalgebras of $\hat\Sigma$.   Let $\sequencen{X_n}$ be a
sequence of $\mu$-integrable real-valued functions such that
$\dom X_n\in\Sigma_n$ and $X_n$ is
$\Sigma_n$-measurable for each $n\in\Bbb N$.   We say that
$\sequencen{X_n}$ is a {\bf submartingale adapted to
$\sequencen{\Sigma_n}$} if
$\int_EX_{n+1}\ge\int_EX_n$ for every
$n\in\Bbb N$ and every $E\in\Sigma_n$.
Prove versions of 275D, 275F, 275G, 275Xf for submartingales.
%275G

\spheader 275Yh Let $\sequencen{X_n}$ be a martingale, and
$\phi:\Bbb R\to\Bbb R$ a convex function.   Show that
$\sequencen{\phi(X_n)}$ is a submartingale.   \Hint{233J.}
Re-examine part (b-ii) of the proof of 275F in the light of
this fact.
%275F, 275Yg, 275G

\spheader 275Yi Let $\sequencen{X_n}$ be an independent sequence of
non-negative random variables all with expectation $1$.   Set
$W_n=X_0\times\ldots\times X_n$ for every $n$.   (i) Show that
$W=\lim_{n\to\infty}W_n$ is defined a.e.\   (ii) Show that $\Expn(W)$ is
either $0$ or $1$.   \Hint{suppose $\Expn(W)>0$.   Set
$Z_n=\lim_{m\to\infty}X_n\times\ldots\times X_m$.   Show that
$\lim_{n\to\infty}Z_n=1$ when $0<W<\infty$, therefore a.e., by the
zero-one law, while $\Expn(Z_n)\le 1$, by Fatou's lemma, so
$\lim_{n\to\infty}\Expn(Z_n)=1$, while
$\Expn(W)=\Expn(W_n)\Expn(Z_{n+1})$ for every $n$.}   (iii) Set
$\gamma=\prod_{n=0}^{\infty}\Expn(\sqrt{X_n})$.   Show that $\gamma>0$
iff $\Expn(W)=1$.
\Hint{$\Pr(W_n\ge\bover14\gamma^2)\ge\bover14\gamma^2$ for every $n$, so
if $\gamma>0$ then $W$ cannot be zero a.e.;  while
$\Expn(\sqrt{W})\le\gamma$.}
%275G

\spheader 275Yj Let $\sequencen{(\Omega_n,\Sigma_n,\mu_n)}$ be a
sequence of probability spaces with product $(\Omega,\Sigma,\mu)$.
Suppose that
for each $n\in\Bbb N$ we have a probability measure $\nu_n$, with domain
$\Sigma_n$, which is absolutely continuous with respect to $\mu_n$, with
Radon-Nikod\'ym derivative $f_n$, and suppose that
$\prod_{n=0}^{\infty}\int\sqrt{f_n}d\mu_n>0$.   Let $\nu$ be the product of $\sequencen{\nu_n}$.   Show that $\nu$ is an
indefinite-integral measure over $\mu$, with Radon-Nikod\'ym derivative
$f$, where $f(\pmb{\omega})=\prod_{n=0}^{\infty}f_n(\omega_n)$ for
$\mu$-almost every $\pmb{\omega}=\sequencen{\omega_n}$ in $\Omega$.
\Hint{use 275Yi to show that $\int fd\mu=1$.}
%275G, 275Yi

\spheader 275Yk Let $\sequencen{p_n}$ be a sequence in $[0,1]$.  Let
$\mu$ be the usual measure on $\{0,1\}^{\Bbb N}$ (254J) and $\nu$ the
product of $\sequencen{\nu_n}$, where $\nu_n$ is the probability measure
on $\{0,1\}$ defined by setting $\nu_n\{1\}=p_n$.   Show that $\nu$ is
an indefinite-integral measure over $\mu$ iff
$\sum_{n=0}^{\infty}|p_n-\bover12|^2<\infty$.
%275Yj, 275G

\spheader 275Yl
Find a martingale $\sequencen{X_n}$ such that the
sequence $\nu_{X_n}$ of distributions (271C) is convergent for the vague
topology (274Ld), but $\sequencen{X_n}$ is not convergent in measure.
%275G added 2002

\spheader 275Ym Let $\sequencen{X_n}$ be an independent sequence of
real-valued random variables such that $\sum_{n=0}^{\infty}X_n$ is defined
in $\Bbb R$ almost everywhere.   Suppose that there is an $M\ge 0$ such
that $|X_n|\le M$ a.e.\ for every $n$.   Show that
$\sum_{n=0}^{\infty}\Expn(X_n)$ is defined in $\Bbb R$.
\Hint{274Yg, 275G.}
%275G

\spheader 275Yn Let $(\Omega,\Sigma,\mu)$ be a probability space and
$\sequencen{X_n}$ an independent sequence of
real-valued random variables on $\Omega$;  set
$E_n=\{\omega:\omega\in\dom X_n$, $|X_n(\omega)|>1\}$,
$Y_n=X_n\times\chi(\Omega\setminus E_n)$ for each $n$, and
$Z_n(\omega)=\med(-1,X_n(\omega),1)$ for $n\in\Bbb N$ and
$\omega\in\dom X_n$.   Show that the following are equiveridical:
(i) $\sum_{n=0}^{\infty}X_n(\omega)$ is defined in $\Bbb R$ for almost
every $\omega$;  (ii) $\sum_{n=0}^{\infty}\hat\mu E_n<\infty$,
$\sum_{n=0}^{\infty}\Expn(Y_n)$ is defined in $\Bbb R$, and
$\sum_{n=0}^{\infty}\Var(Y_n)<\infty$, where $\hat\mu$ is the completion of
$\mu$;
(iii) $\sum_{n=0}^{\infty}\hat\mu E_n<\infty$,
$\sum_{n=0}^{\infty}\Expn(Z_n)$ is defined in $\Bbb R$, and
$\sum_{n=0}^{\infty}\Var(Z_n)<\infty$.   \Hint{273K, 275Ym.}
(This is a version of the {\bf Three Series Theorem}.)
%275Ym 275G 273K

\spheader 275Yo Let $(\Omega,\Sigma,\mu)$ be a probability
space, $\sequencen{\Sigma_n}$ a non-decreasing sequence of
$\sigma$-subalgebras of $\Sigma$ and $\sequencen{X_n}$ a sequence of
random variables on $\Omega$ such that
$\Expn(\sup_{n\in\Bbb N}|X_n|)$ is finite
and $X=\lim_{n\to\infty}X_n$ is defined almost everywhere.
For each $n$, let $Y_n$ be a conditional expectation of $X_n$ on
$\Sigma_n$.   Show that $\sequencen{Y_n}$ converges almost everywhere to
a conditional expectation of $X$ on the $\sigma$-algebra generated by
$\bigcup_{n\in\Bbb N}\Sigma_n$.
%275I %mt27bits

\spheader 275Yp Show that 275Yo can fail if $\sequencen{X_n}$ is
merely uniformly integrable, rather than dominated by an integrable
function.
%275Yo, 275I  %mt27bits

\spheader 275Yq Let $(\Omega,\Sigma,\mu)$ be a complete probability
space, and $\sequencen{X_n}$ an independent sequence of random variables
on $\Omega$, all with the same distribution, and of finite expectation.
For each $n$, set $S_n=\bover1{n+1}(X_0+\ldots+X_n)$;  let $\Sigma_n$ be
the $\sigma$-algebra defined by $S_n$ and $\Sigma_n^*$ the
$\sigma$-algebra generated by $\bigcup_{m\ge n}\Sigma_m$.   Show that
$S_n$ is a conditional expectation of $X_0$ on $\Sigma_n^*$.
\Hint{assume every $X_i$ defined everywhere on $\Omega$.   Set
$\phi(\omega)=\sequence{i}{X_i(\omega)}$.   Show that
$\phi:\Omega\to\BbbR^{\Bbb N}$ is \imp\ for a suitable product measure
on $\BbbR^{\Bbb N}$, and that every set in $\Sigma_n^*$ is of the form
$\phi^{-1}[H]$ where $H\subseteq\BbbR^{\Bbb N}$ is a Borel set
invariant under permutations of coordinates in the set $\{0,\ldots,n\}$,
so that $\int_EX_i=\int_EX_j$ whenever $i\le j\le n$ and
$E\in\Sigma_n^*$.}   Hence show that $\sequencen{S_n}$ converges almost
everywhere.   (Compare 273I.)
%275K

\spheader 275Yr Formulate and prove versions of the
results of this section for martingales consisting of functions taking
values in $\Bbb C$ or $\BbbR^r$ rather than $\Bbb R$.
}%end of exercises

\cmmnt{
\Notesheader{275} I hope that the sketch above, though distressingly
abbreviated, has suggested some of the richness of the concepts
involved, and will provide a foundation for further study.   All the
theorems of this section have far-reaching implications, but the one
which is simply indispensable in advanced measure theory is 275I,
`L\'evy's martingale convergence theorem', which I will use in the proof
of the Lifting Theorem in Chapter 34 of the next volume.

As for stopping times, I mention them partly in an attempt to cast
further light on what martingales are for (see 276Ed below), and partly
because the ideas of 275N-275O are so important in modern probability
theory that, just as a matter of general knowledge, you should be aware
that there is something there.   I add 275P as one of the most
accessible of the standard results which may be obtained by this method.

}%end of notes

\discrpage

